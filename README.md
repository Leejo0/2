3. TensorFlow Datasets ê¸°ë³¸ ì‚¬ìš©
import tensorflow_datasets as tfds



# íŒ¨ì…˜ MNIST ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
data = tfds.load('fashion_mnist', with_info=True, as_supervised=True)
train_data, test_data = data['train'], data['test']

print(train_data)



ğŸ” ì‹¤í–‰ ê²°ê³¼

train_dataì™€ test_dataë¡œ ìë™ ë¶„ë¦¬
ê° ë°ì´í„°ëŠ” (image, label) ìŒìœ¼ë¡œ êµ¬ì„±ëœ tf.data.Dataset ê°ì²´
MNISTì˜ ê²½ìš°: 28Ã—28 í‘ë°± ì´ë¯¸ì§€ 60,000ì¥ + í…ŒìŠ¤íŠ¸ 10,000ì¥




4. ì¼€ë¼ìŠ¤ ëª¨ë¸ì— ë°ì´í„°ì…‹ ì—°ê²°
import tensorflow as tf
import tensorflow_datasets as tfds

(train_images, train_labels), (test_images, test_labels) = \
  tfds.as_numpy(tfds.load('fashion_mnist', split=['train', 'test'], as_supervised=True, batch_size=-1))

train_images = tf.cast(train_images, tf.float32) / 255.0
test_images = tf.cast(test_images, tf.float32) / 255.0

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28,28,1)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(train_images, train_labels, epochs=5)





ğŸ“ˆ ê²°ê³¼ ìš”ì•½

ì •í™•ë„ ì•½ 0.88~0.91
Dropout(0.2)ë¡œ ê³¼ì í•© ì™„í™”
TFDS ë°ì´í„°ì…‹ì€ ì¼€ë¼ìŠ¤ ëª¨ë¸ì— ë°”ë¡œ ì—°ê²° ê°€ëŠ¥



5. ë°ì´í„° ì¦ì‹(Augmentation) ì ìš©í•˜ê¸°
def augmentimages(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    image = tf.image.random_flip_left_right(image)
    return image, label

train_data = train_data.map(augmentimages)





âš™ï¸ ì„¤ëª…

map() í•¨ìˆ˜ë¥¼ í†µí•´ ë°ì´í„°ì…‹ ì „ì²´ì— ì¦ê°• í•¨ìˆ˜ë¥¼ ì ìš©

tf.image.random_flip_left_right() : ì¢Œìš° ë°˜ì „

ë°ì´í„° ë‹¤ì–‘ì„±ì„ ë†’ì—¬ ê³¼ì í•© ë°©ì§€ íš¨ê³¼

6. TensorFlow Addonsë¥¼ í™œìš©í•œ ê³ ê¸‰ ì¦ê°•
import tensorflow_addons as tfa

def augmentimages(image, label):
    image = tf.cast(image, tf.float32) / 255.0
    image = tf.image.random_flip_left_right(image)
    image = tfa.image.rotate(image, 40, interpolation='NEAREST')
    return image, label




ğŸ” ê²°ê³¼

íšŒì „ + ë°˜ì „ ë“± ë³µí•© ì¦ê°•ìœ¼ë¡œ ë°ì´í„° ë‹¤ì–‘ì„± ê°•í™”

ëª¨ë¸ì´ ë” ì¼ë°˜í™”ë˜ì–´ í…ŒìŠ¤íŠ¸ ì •í™•ë„ 2~4% ìƒìŠ¹




7. ì‚¬ìš©ì ì •ì˜ ë°ì´í„° ë¶„í• 
data = tfds.load('cats_vs_dogs', split='train[:80%]', as_supervised=True)
val_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', as_supervised=True)
test_data = tfds.load('cats_vs_dogs', split='train[90%:]', as_supervised=True)




ğŸ“˜ ì„¤ëª…

split êµ¬ë¬¸ìœ¼ë¡œ ë°ì´í„°ì…‹ ì¼ë¶€ë§Œ ë¡œë“œ ê°€ëŠ¥

ë¹„ìœ¨(:80%, 80%:90%) ë˜ëŠ” ê°œìˆ˜(:10000, -1000:) ì§€ì •

ëª¨ë¸ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ìœ ì—°í•˜ê²Œ êµ¬ì„± ê°€ëŠ¥

8. TFRecord ì´í•´í•˜ê¸°
data, info = tfds.load('mnist', with_info=True)
print(info)

filename = '/root/tensorflow_datasets/mnist/3.0.1/mnist-train.tfrecord-00000-of-00001'
raw_dataset = tf.data.TFRecordDataset(filename)

for raw_record in raw_dataset.take(1):
    print(repr(raw_record))




ğŸ” ê°œë… ìš”ì•½

TFRecord: TensorFlow ì „ìš© ë°”ì´ë„ˆë¦¬ ë°ì´í„° í¬ë§·

ëŒ€ê·œëª¨ ë°ì´í„° ì €ì¥ ì‹œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

tf.data.TFRecordDataset()ìœ¼ë¡œ ì§ì ‘ ì½ê¸° ê°€ëŠ¥




ğŸ’¡ ì‹¤ìŠµ ê²°ê³¼

ì¶œë ¥: ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬(PNG) + ë¼ë²¨ ì •ë³´

ë¹ ë¥¸ ë¡œë”© 




9. ETL í”„ë¡œì„¸ìŠ¤ (Extract, Transform, Load)
ğŸ§¾ ê°œë… ìš”ì•½

ETLì€ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬

ë‹¨ê³„	ì„¤ëª…
ì¶”ì¶œ(Extract)	ì›ë³¸ ë°ì´í„°ë¥¼ ë¡œë“œ (TFDS, ë¡œì»¬ íŒŒì¼ ë“±)
ë³€í™˜(Transform)	ì¦ê°•, ì •ê·œí™”, ì „ì²˜ë¦¬ ìˆ˜í–‰
ë¡œë“œ(Load)	GPU/TPUì— ë°°ì¹˜ ì „ë‹¬ ë° í•™ìŠµ ìˆ˜í–‰
10. ETL ì „ì²´ ì˜ˆì œ ìš”ì•½
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_addons as tfa

data = tfds.load('horses_or_humans', split='train', as_supervised=True)
val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)

def augment(image, label):
    image = tf.cast(image, tf.float32)/255.0
    image = tf.image.random_flip_left_right(image)
    image = tfa.image.rotate(image, 40, interpolation='NEAREST')
    return image, label

train = data.map(augment).shuffle(100).batch(32)
val = val_data.batch(32)

model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300,300,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(train, epochs=10, validation_data=val)

ğŸ“ˆ ì‹¤í–‰ ê²°ê³¼

ì¦ê°• ì ìš© ì‹œ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ



11. ë¡œë“œ ë‹¨ê³„ ìµœì í™” (CPU â†’ GPU/TPU íŒŒì´í”„ë¼ì¸)

ë°ì´í„° ì¶”ì¶œ/ë³€í™˜ì€ CPU,
ë¡œë“œ ë° í•™ìŠµì€ GPU/TPUì—ì„œ ìˆ˜í–‰

tf.dataì˜ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ë¥¼ í†µí•´ I/O ë³‘ëª©ì„ ìµœì†Œí™”

prefetch()ì™€ cache()ë¥¼ í™œìš©í•˜ë©´ í•™ìŠµ ì†ë„ë¥¼ í–¥ìƒ

12. ğŸ’¡ ì‹¤ìŠµ ìš”ì•½ ë° ì‹œì‚¬ì 
í•­ëª©	ë‚´ìš©
ë°ì´í„° ìë™í™”	tfds.load()ë¡œ ë°ì´í„° ë¡œë“œ ë° ë¶„í•  ìë™í™”
ì¦ê°• ì²˜ë¦¬	tf.image, tfa.imageë¡œ ê°„ë‹¨í•œ ì´ë¯¸ì§€ ì¦ì‹
íš¨ìœ¨ì  ì €ì¥	TFRecordë¥¼ í†µí•œ ëŒ€ìš©ëŸ‰ ë°ì´í„° ê´€ë¦¬
ì„±ëŠ¥ ìµœì í™”	ETL ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬
í•™ìŠµ íš¨ìœ¨	ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì˜ ë‹¨ìˆœí™” ë° ëª¨ë¸ ì¼ë°˜í™” í–¥ìƒ


âœ… ê²°ë¡ 

TensorFlow Datasetsë¥¼ ì‚¬ìš©í•˜ë©´
1ï¸âƒ£ ë°ì´í„° ì¤€ë¹„ ì‹œê°„ ë‹¨ì¶•,
2ï¸âƒ£ ì „ì²˜ë¦¬ ë° ì¦ê°• ìë™í™”,
3ï¸âƒ£ ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ,
4ï¸âƒ£ ëŒ€ê·œëª¨ ë°ì´í„° ê´€ë¦¬ íš¨ìœ¨ ê·¹ëŒ€í™”

ì´ ì¥ì˜ í•µì‹¬ : ë°ì´í„°ì…‹ì„ ì†ì‰½ê²Œ ë¶ˆëŸ¬ì˜¤ê³ , ìë™í™”ëœ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ í•™ìŠµ íš¨ìœ¨ì„ ë†’ì´ëŠ” ê²ƒ
